---
Title: BDB backup/export location object
linkTitle: backup_location/export_location
description: Documents the bdb backup_location/export_location object used with Redis Enterprise Software REST API calls.
weight: $weight
alwaysopen: false
categories: ["RS"]
---

You can back up or export a database's dataset to the following types of locations:

-   FTP/S
-   SFTP
-   Amazon S3
-   Google Cloud Storage
-   Microsoft Azure Storage
-   OpenStack Object Storage (also known as "Swift")
-   NAS/Local Storage

## Basic parameters

For all backup/export location objects, you need to specify the location type via the `type` field.

| Location type | "type" value |
|---------------|--------------|
| FTP/S | "url" |
| SFTP | "sftp" |
| Amazon S3 | "s3" |
| Google Cloud Storage | "gs" |
| Microsoft Azure Storage | "abs" |
| OpenStack Object Storage ("Swift") | "swift" |
| NAS/Local Storage | "mount_point" |

## Location-specific parameters

Any additional required parameters may differ based on the backup/export location type.

### FTP

| Key name | Type | Description |
|----------|------|-------------|
| url | string | A URI that represents a FTP/S location with the following format: `ftp://user:password@host:port/path/`. The user and password can be omitted if not needed. |

### SFTP

| Key name | Type | Description |
|----------|------|-------------|
| sftp_url | string | SFTP URL in the format: `sftp://user:password@host[:port][/path/]`. The default port number is 22 and the default path is '/'. |
| key | string | SSH private key to secure the SFTP server connection. If you do not specify an SSH private key, the autogenerated private key of the cluster is used, and you must add the SSH public key of the cluster to the SFTP server configuration. (optional) |

### AWS S3

| Key name | Type | Description |
|----------|------|-------------|
| bucket_name | string | S3 bucket name |
| subdir | string | Path to the backup directory in the S3 bucket (optional) |
| access_key_id | string | The AWS Access Key ID with access to the bucket |
| secret_access_key | string | The AWS Secret Access Key that matches the Access Key ID |

### Google Cloud Storage

| Key name | Type | Description |
|----------|------|-------------|
| bucket_name | string | Cloud Storage bucket name |
| subdir | string | Path to the backup directory in the Cloud Storage bucket (optional) |
| client_id | string | Cloud Storage client ID with access to the Cloud Storage bucket |
| client_email | string | Email address for the Cloud Storage client ID |
| private_key_id | string | Cloud Storage private key ID with access to the Cloud Storage bucket |
| private_key | string | Cloud Storage private key that matches the private key ID |

### Azure Blob Storage

| Key name | Type | Description |
|----------|------|-------------|
| container | string | Blob Storage container name |
| subdir | string | Path to the backup directory in the Blob Storage container (optional) |
| account_name | string | Storage account name with access to the container |
| account_key | string | Access key for the storage account |
| sas_token | string | Token to authenticate with shared access signature |

{{<note>}}
`account_key` and `sas_token` are mutually exclusive
{{</note>}}

### Swift

| Key name | Type | Description |
|----------|------|-------------|
| auth_url | string | Swift service authentication URL |
| user | string | Swift service username |
| key | string | Swift service key that corresponds to the username |
| container | string | The name of the Swift object store container to back up to |
| prefix | string | Swift path to use as a prefix for the filenames for the backup files (optional) |

### NAS/Local Storage

| Key name | Type | Description |
|----------|------|-------------|
| path | string | Path to the local mount point. You must create the mount point on all nodes, and the `redislabs:redislabs` user must have read and write permissions on the local mount point. |
