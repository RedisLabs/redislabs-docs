---
Title: BDB dataset import sources object
linkTitle: dataset_import_sources
description: Documents the bdb dataset_import_sources object used with Redis Enterprise Software REST API calls.
weight: $weight
alwaysopen: false
categories: ["RS"]
---

You can import data to a database from the following location types:

-   HTTP/S
-   FTP
-   SFTP
-   Amazon S3
-   Google Cloud Storage
-   Microsoft Azure Storage
-   OpenStack Object Storage (also known as “Swift”)
-   NAS/Local Storage

The source file to import should be in the [RDB]({{<relref "/rs/concepts/data-access/persistence">}}) format. It can also be in a compressed (gz) RDB file.

Supply an array of dataset import source objects to import data from multiple files.

## Basic parameters

For all import location objects, you need to specify the location type via the `type` field.

| Location type | "type" value |
|---------------|--------------|
| FTP/S | "url" |
| SFTP | "sftp" |
| Amazon S3 | "s3" |
| Google Cloud Storage | "gs" |
| Microsoft Azure Storage | "abs" |
| OpenStack Object Storage ("Swift") | "swift" |
| NAS/Local Storage | "mount_point" |

## Location-specific parameters

Any additional required parameters may differ based on the import location type.

### FTP

| Key name | Type | Description |
|----------|------|-------------|
| url | string | A URI that represents the FTP/S location with the following format: `ftp://user:password@host:port/path/`. The user and password can be omitted if not needed. |

### SFTP

| Key name | Type | Description |
|----------|------|-------------|
| sftp_url | string | SFTP URL in the format: `sftp://user:password@host[:port]/path/filename.rdb`. The default port number is 22 and the default path is '/'. |
| key | string | SSH private key to secure the SFTP server connection. If you do not specify an SSH private key, the autogenerated private key of the cluster is used, and you must add the SSH public key of the cluster to the SFTP server configuration. (optional) |

### AWS S3

| Key name | Type | Description |
|----------|------|-------------|
| bucket_name | string | S3 bucket name |
| subdir | string | Path to the backup directory in the S3 bucket (optional) |
| access_key_id | string | The AWS Access Key ID with access to the bucket |
| secret_access_key | string | The AWS Secret Access that matches the Access Key ID |

### Google Cloud Storage

| Key name | Type | Description |
|----------|------|-------------|
| bucket_name | string | Cloud Storage bucket name |
| subdir | string | Path to the backup directory in the Cloud Storage bucket (optional) |
| client_id | string | Cloud Storage client ID with access to the Cloud Storage bucket |
| client_email | string | Email address for the Cloud Storage client ID |
| private_key_id | string | Cloud Storage private key ID with access to the Cloud Storage bucket |
| private_key | string | Private key for the Cloud Storage matching the private key ID |

### Azure Blob Storage

| Key name | Type | Description |
|----------|------|-------------|
| container | string | Blob Storage container name |
| subdir | string | Path to the backup directory in the Blob Storage container (optional) |
| account_name | string | Storage account name with access to the container |
| account_key | string | Access key for the storage account |
| sas_token | string | Token to authenticate with shared access signature |

{{<note>}}
`account_key` and `sas_token` are mutually exclusive
{{</note>}}

### Swift

| Key name | Type | Description |
|----------|------|-------------|
| auth_url | string | Swift service authentication URL |
| user | string | Swift service username to access the storage |
| key | string | Swift service key corresponding to the username |
| container | string | Name of the Swift object store container that contains the import source file |
| objname | string | Swift object name (filename) of the import source file |
| prefix | string | Swift path to use as a prefix to the object name for the import source file (optional) |

### NAS/Local Storage

| Key name | Type | Description |
|----------|------|-------------|
| path | string | Path to the locally mounted filename to import. You must create the mount point on all nodes, and the `redislabs:redislabs` user must have read permissions on the local mount point.
